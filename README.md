# Introduction

We introduce an extra visual transformer as the alignment-ware image encoder and an extra text transformer as the alignment ware text encoder before multimodal fusion. We consider alignment in the following three aspects: 1) document-level alignment by leveraging the cross-modal and intra-modal contrastive loss; 2) global-local alignment for modeling localized and structural information in document images; and 3) local-level alignment for more accurate patch-level information. For more details, please refer to our paper:  **Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models[pdf]**


